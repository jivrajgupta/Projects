import pandas as pd
import numpy as np
from sklearn.metrics import precision_recall_fscore_support

# Generate example data
np.random.seed(0)
num_samples = 1000
num_classes = 10
class_labels = [f'Class {i}' for i in range(1, num_classes + 1)]
predictions = np.random.randint(1, num_classes + 1, size=num_samples)
ground_truth = np.random.randint(1, num_classes + 1, size=num_samples)

# Calculate precision, recall, and F1 score
precision, recall, f1_score, _ = precision_recall_fscore_support(ground_truth, predictions, average=None)
average_precision, average_recall, average_f1_score, _ = precision_recall_fscore_support(ground_truth, predictions, average='macro')

# Create DataFrame
report_df = pd.DataFrame({'Class': class_labels,
                          'Precision': precision,
                          'Recall': recall,
                          'F1 Score': f1_score})

# Add row for average values
report_df.loc[len(report_df)] = ['Average', average_precision, average_recall, average_f1_score]

print(report_df)
